{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# TME 10-11 : Visualisation de réseaux de neurones\n",
    "\n",
    "## Chargement des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "torchvision.models.vgg.model_urls[\n",
    "    \"squeezenet1_1\"] = \"http://webia.lip6.fr/~douillard/rdfia/squeezenet1_1-f364aa15.pth\"\n",
    "os.environ[\"TORCH_HOME\"] = \"/tmp/torch\"\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'viridis'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions et variables utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQUEEZENET_MEAN = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "SQUEEZENET_STD = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "\n",
    "def preprocess(img, size=224):\n",
    "    transform = T.Compose([\n",
    "        T.Resize((size, size)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=SQUEEZENET_MEAN.tolist(),\n",
    "                    std=SQUEEZENET_STD.tolist()),\n",
    "        T.Lambda(lambda x: x[None]),\n",
    "    ])\n",
    "    return transform(img)\n",
    "\n",
    "def deprocess(img, should_rescale=True):\n",
    "    transform = T.Compose([\n",
    "        T.Lambda(lambda x: x[0]),\n",
    "        T.Normalize(mean=[0, 0, 0], std=(1.0 / SQUEEZENET_STD).tolist()),\n",
    "        T.Normalize(mean=(-SQUEEZENET_MEAN).tolist(), std=[1, 1, 1]),\n",
    "        T.Lambda(rescale) if should_rescale else T.Lambda(lambda x: x),\n",
    "        T.ToPILImage(),\n",
    "    ])\n",
    "    return transform(img)\n",
    "\n",
    "def rescale(x):\n",
    "    low, high = x.min(), x.max()\n",
    "    x_rescaled = (x - low) / (high - low)\n",
    "    return x_rescaled\n",
    "    \n",
    "def blur_image(X_np, sigma=1):\n",
    "    X_np = gaussian_filter1d(X_np, sigma, axis=2)\n",
    "    X_np = gaussian_filter1d(X_np, sigma, axis=3)\n",
    "    return torch.tensor(X_np)\n",
    "\n",
    "def jitter(X, ox, oy):\n",
    "    \"\"\"\n",
    "    Helper function to randomly jitter an image.\n",
    "    \n",
    "    Inputs\n",
    "    - X: PyTorch Tensor of shape (N, C, H, W)\n",
    "    - ox, oy: Integers giving number of pixels to jitter along W and H axes\n",
    "    \n",
    "    Returns: A new PyTorch Tensor of shape (N, C, H, W)\n",
    "    \"\"\"\n",
    "    if ox != 0:\n",
    "        left = X[:, :, :, :-ox]\n",
    "        right = X[:, :, :, -ox:]\n",
    "        X = torch.cat([right, left], dim=3)\n",
    "    if oy != 0:\n",
    "        top = X[:, :, :-oy]\n",
    "        bottom = X[:, :, -oy:]\n",
    "        X = torch.cat([bottom, top], dim=2)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement du modèle\n",
    "\n",
    "Pour ce TME, on utilisera le modèle Squeezenet qui est une modèle léger pré-appris sur ImageNet. Ce modèle sera figé puisque le but n'est pas de modifier/apprendre ses poids mais de les étudier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du modèle\n",
    "model = torchvision.models.squeezenet1_1(pretrained=True)\n",
    "\n",
    "# Modele en mode test\n",
    "model.eval()\n",
    "\n",
    "# Freeze les poids\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement d'images d'exemples\n",
    "\n",
    "Permet de chargement dans les variables `X, y, class_names` 25 exemples de l'ensemble de validation d'ImageNet. `X` contient les images, `y` l'indice de la classe de chaque images, et `class_names` un dictionnaire permet d'obtenir le nom d'une classe à partir de son numéro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.load(\"imagenet_val_25.npz\", allow_pickle=True)\n",
    "X, y, class_names = f[\"X\"], f[\"y\"], f[\"label_map\"].item()\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "for i in range(24):\n",
    "    plt.subplot(4, 6, i + 1)\n",
    "    plt.imshow(X[i])\n",
    "    plt.title(class_names[y[i]])\n",
    "    plt.axis('off')\n",
    "plt.gcf().tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saliency Maps\n",
    "\n",
    "Calculez la carte de saillance pour 5 exemples parmi les 25 chargés selon les instructions du sujet de TP.\n",
    "\n",
    "**Conseil :** Pour sélectionner 1 valeur particulière pour chaque ligne d'une matrice, vous pouvez faire comme cela :\n",
    "\n",
    "```python\n",
    "x = torch.Tensor([[0.1, 0.0, 0.5, 0.1, 0.1],\n",
    "                  [0.0, 0.1, 0.0, 0.6, 0.2],\n",
    "                  [0.7, 0.1, 0.1, 0.3, 0.0]])\n",
    "x[np.arange(3), [2, 3, 0]]\n",
    "# 0.5000\n",
    "# 0.6000\n",
    "# 0.7000\n",
    "#[torch.FloatTensor of size 3]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_saliency_maps(X, y, model):\n",
    "    \"\"\"\n",
    "    Compute a class saliency map using the model for images X and labels y.\n",
    "\n",
    "    Input:\n",
    "    - X: Input images; Tensor of shape (N, 3, H, W)\n",
    "    - y: Labels for X; LongTensor of shape (N,)\n",
    "    - model: A pretrained CNN that will be used to compute the saliency map.\n",
    "\n",
    "    Returns:\n",
    "    - saliency: A Tensor of shape (N, H, W) giving the saliency maps for the input\n",
    "    images.\n",
    "    \"\"\"\n",
    "    X.requires_grad=True\n",
    "\n",
    "    saliency = None\n",
    "    ##############################################################################\n",
    "    # TODO: Implement this function. Perform a forward and backward pass through #\n",
    "    # the model to compute the gradient of the correct class score with respect  #\n",
    "    # to each input image. You first want to compute the loss over the correct   #\n",
    "    # scores, and then compute the gradients with a backward pass.               #\n",
    "    ##############################################################################\n",
    "    pass\n",
    "    ##############################################################################\n",
    "    #                             END OF YOUR CODE                               #\n",
    "    ##############################################################################\n",
    "    return saliency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testez votre code avec la fonction ci-dessous :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def show_saliency_maps(X, y, model):\n",
    "    # Convert X and y from numpy arrays to Torch Tensors\n",
    "    X_tensor = torch.cat([preprocess(Image.fromarray(x)) for x in X], dim=0)\n",
    "    y_tensor = torch.LongTensor(y)\n",
    "\n",
    "    # Compute saliency maps for images in X\n",
    "    saliency = compute_saliency_maps(X_tensor, y_tensor, model)\n",
    "\n",
    "    # Convert the saliency map from Torch Tensor to numpy array and show images\n",
    "    # and saliency maps together.\n",
    "    saliency = saliency.numpy()\n",
    "    N = X.shape[0]\n",
    "    for i in range(N):\n",
    "        plt.subplot(2, N, i + 1)\n",
    "        plt.imshow(X[i])\n",
    "        plt.axis('off')\n",
    "        plt.title(class_names[y[i]])\n",
    "        plt.subplot(2, N, N + i + 1)\n",
    "        plt.imshow(saliency[i], cmap=plt.cm.hot)\n",
    "        plt.axis('off')\n",
    "        plt.gcf().set_size_inches(12, 5)\n",
    "    plt.show()\n",
    "\n",
    "for i in range(1): # range(5) pour tester toutes les images\n",
    "    show_saliency_maps(X[5*i:5*i+5], y[5*i:5*i+5], model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fooling Images\n",
    "\n",
    "Ecrire le code pour calculer une image de facon à ce qu'elle soit classée dans une classe `target_y` autre que la classe réelle (en modifiant l'image et pas les poids du réseau). Voir le sujet de TP pour les instructions.\n",
    "\n",
    "Les 2 premiers blocs permettent de faire des tests de facon interractive pour écrire votre code. Une fois que votre code semble fonctionner, compléter la fonction dans le 3e bloc et tester sur differentes images avec le 4e bloc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init du test\n",
    "X_tensor = torch.Tensor(preprocess(Image.fromarray(X[0])))\n",
    "target_y = 6\n",
    "X_fooling = X_tensor.clone()\n",
    "X_fooling.requires_grad = True\n",
    "learning_rate = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO ecrire votre code a tester ici\n",
    "\n",
    "\n",
    "\n",
    "# Affichage de l'image X_fooling et ses modifs\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(np.asarray(deprocess(X_fooling.clone())).astype(np.uint8))\n",
    "plt.title(\"Image X_fooling\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(np.asarray(deprocess(10* (X_fooling - X_tensor), should_rescale=False)))\n",
    "plt.title(\"Difference avec X_tensor magnifiée (x10)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fooling_image(X, target_y, model, nb_iterations=100):\n",
    "    \"\"\"\n",
    "    Generate a fooling image that is close to X, but that the model classifies\n",
    "    as target_y.\n",
    "\n",
    "    Inputs:\n",
    "    - X: Input image; Tensor of shape (1, 3, 224, 224)\n",
    "    - target_y: An integer in the range [0, 1000)\n",
    "    - model: A pretrained CNN\n",
    "\n",
    "    Returns:\n",
    "    - X_fooling: An image that is close to X, but that is classifed as target_y\n",
    "    by the model.\n",
    "    \"\"\"\n",
    "    # Initialize our fooling image to the input image, and wrap it in a Variable.\n",
    "    X_fooling = X.clone()\n",
    "    X_fooling.requires_grad = True\n",
    "    \n",
    "    learning_rate = 0.1\n",
    "    ##############################################################################\n",
    "    # TODO: Generate a fooling image X_fooling that the model will classify as   #\n",
    "    # the class target_y. You should perform gradient ascent on the score of the #\n",
    "    # target class, stopping when the model is fooled.                           #\n",
    "    # When computing an update step, first normalize the gradient:               #\n",
    "    #   dX = learning_rate * g / ||g||_2                                         #\n",
    "    #                                                                            #\n",
    "    # You should write a training loop.                                          #\n",
    "    #                                                                            #\n",
    "    # HINT: For most examples, you should be able to generate a fooling image    #\n",
    "    # in fewer than 100 iterations of gradient ascent.                           #\n",
    "    # You can print your progress over iterations to check your algorithm.       #\n",
    "    ##############################################################################\n",
    "    pass\n",
    "    ##############################################################################\n",
    "    #                             END OF YOUR CODE                               #\n",
    "    ##############################################################################\n",
    "    return X_fooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Indice de l'image a modifier et de la classe cible\n",
    "idx = 1\n",
    "target_y = 6\n",
    "\n",
    "# Preparation du tenseur X et sa version \"fooling\"\n",
    "X_tensor = torch.cat([preprocess(Image.fromarray(x)) for x in X], dim=0)\n",
    "X_fooling = make_fooling_image(X_tensor[idx:idx+1], target_y, model)\n",
    "\n",
    "# verification de la classe predite\n",
    "scores = model(X_fooling)\n",
    "assert target_y == scores.data.max(1)[1][0], 'The model is not fooled!'\n",
    "\n",
    "# Affichage\n",
    "X_fooling_np = deprocess(X_fooling.clone())\n",
    "X_fooling_np = np.asarray(X_fooling_np).astype(np.uint8)\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(X[idx])\n",
    "plt.title(class_names[y[idx]])\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(X_fooling_np)\n",
    "plt.title(class_names[target_y])\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "X_pre = preprocess(Image.fromarray(X[idx]))\n",
    "diff = np.asarray(deprocess(X_fooling - X_pre, should_rescale=False))\n",
    "plt.imshow(diff)\n",
    "plt.title('Difference')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "diff = np.asarray(deprocess(10 * (X_fooling - X_pre), should_rescale=False))\n",
    "plt.imshow(diff)\n",
    "plt.title('Magnified difference (10x)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.gcf().set_size_inches(12, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class visualization\n",
    "\n",
    "Ecrire le code permettant de calculer une image maximisant le score d'une classe, sujet à un certain nombre de régularisations. Voir le sujet pour les details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_class_visualization(target_y, model, dtype, init_img=None, l2_reg=1e-3, learning_rate=5,\n",
    "                               num_iterations=200, blur_every=10, max_jitter=16, show_every=25):\n",
    "    \"\"\"\n",
    "    Generate an image to maximize the score of target_y under a pretrained model.\n",
    "    \n",
    "    Inputs:\n",
    "    - target_y: Integer in the range [0, 1000) giving the index of the class\n",
    "    - model: A pretrained CNN that will be used to generate the image\n",
    "    - dtype: Torch datatype to use for computations\n",
    "    \n",
    "    Keyword arguments:\n",
    "    - init_img: Initial image to use (if None, will be random)\n",
    "    - l2_reg: Strength of L2 regularization on the image\n",
    "    - learning_rate: How big of a step to take\n",
    "    - num_iterations: How many iterations to use\n",
    "    - blur_every: How often to blur the image as an implicit regularizer\n",
    "    - max_jitter: How much to gjitter the image as an implicit regularizer\n",
    "    - show_every: How often to show the intermediate result\n",
    "    \"\"\"\n",
    "    model.type(dtype)\n",
    "\n",
    "    # Randomly initialize the image as a PyTorch Tensor:\n",
    "    if init_img is None:\n",
    "        img = torch.randn(1, 3, 224, 224).mul_(1.0).type(dtype)\n",
    "    else:\n",
    "        img = init_img.clone().mul_(1.0).type(dtype)\n",
    "    img.requires_grad = True\n",
    "\n",
    "    for t in range(num_iterations):\n",
    "        # Randomly jitter the image a bit; this gives slightly nicer results\n",
    "        ox, oy = random.randint(0, max_jitter), random.randint(0, max_jitter)\n",
    "        img.data.copy_(jitter(img.data, ox, oy))\n",
    "\n",
    "        ########################################################################\n",
    "        # TODO: Use the model to compute the gradient of the score for the     #\n",
    "        # class target_y with respect to the pixels of the image, and make a   #\n",
    "        # gradient step on the image using the learning rate. Don't forget the #\n",
    "        # L2 regularization term!                                              #\n",
    "        # Be very careful about the signs of elements in your code.            #\n",
    "        ########################################################################\n",
    "        pass\n",
    "        ########################################################################\n",
    "        #                             END OF YOUR CODE                         #\n",
    "        ########################################################################\n",
    "        \n",
    "        # Undo the random jitter\n",
    "        img.data.copy_(jitter(img.data, -ox, -oy))\n",
    "\n",
    "        # As regularizer, clamp and periodically blur the image\n",
    "        for c in range(3):\n",
    "            lo = float(-SQUEEZENET_MEAN[c] / SQUEEZENET_STD[c])\n",
    "            hi = float((1.0 - SQUEEZENET_MEAN[c]) / SQUEEZENET_STD[c])\n",
    "            img.data[:, c].clamp_(min=lo, max=hi)\n",
    "        if t % blur_every == 0:\n",
    "            img.data = blur_image(img.data.cpu().numpy(), sigma=0.5)\n",
    "        \n",
    "        # Periodically show the image\n",
    "        if t == 0 or (t + 1) % show_every == 0 or t == num_iterations - 1:\n",
    "            plt.imshow(deprocess(img.clone().cpu()))\n",
    "            class_name = class_names[target_y]\n",
    "            plt.title('%s\\nIteration %d / %d' % (class_name, t + 1, num_iterations))\n",
    "            plt.gcf().set_size_inches(4, 4)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "    return deprocess(img.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test avec diverses classes en partant d'un bruit aléatoire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtype = torch.FloatTensor\n",
    "# dtype = torch.cuda.FloatTensor # Uncomment this to use GPU\n",
    "model.type(dtype)\n",
    "\n",
    "target_y = 281 # Tabby cat\n",
    "# target_y = 187 # Yorkshire Terrier\n",
    "# target_y = 76 # Tarantula\n",
    "# target_y = 78 # Tick\n",
    "# target_y = 683 # Oboe\n",
    "# target_y = 366 # Gorilla\n",
    "# target_y = 604 # Hourglass\n",
    "# target_y = np.random.randint(1000) # Classe aléatoire\n",
    "out = create_class_visualization(target_y, model, dtype, show_every=25, num_iterations=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test en partant d'une image d'ImageNet :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init du test\n",
    "img_ind = 4\n",
    "\n",
    "target_y = y[img_ind]\n",
    "X_tensor = torch.Tensor(preprocess(Image.fromarray(X[img_ind])))\n",
    "out = create_class_visualization(target_y, model, dtype, init_img=X_tensor, show_every=25, num_iterations=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
